{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from IPython.display import Image, display, SVG\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input, LSTM, Dense, GRU, Dropout,TimeDistributed,Merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.xlabel('True label')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def filter_empty_entires(features, labels):\n",
    "    valid_indexes = []\n",
    "    \n",
    "    nr_timesteps = features.shape[1]\n",
    "    nr_features = features.shape[2]\n",
    "    \n",
    "    for index, feature in enumerate(features):\n",
    "        elem_sum = np.sum(feature)\n",
    "        if elem_sum != nr_timesteps*nr_features*-1:\n",
    "            valid_indexes.append(index)\n",
    "            \n",
    "    return features[valid_indexes], labels[valid_indexes]\n",
    "    \n",
    "    \n",
    "def get_mock_df(pred_df, data_channel_folder, round_decimals):\n",
    "    \n",
    "    data_channel_random_take_path = data_channel_folder + sorted(os.listdir(data_channel_folder))[4] # hack\n",
    "    \n",
    "    columns = read_df(data_channel_random_take_path, \\\n",
    "                      channel_columns[os.path.basename(data_channel_folder[:-1])], \\\n",
    "                      round_decimals,\n",
    "                      no_drop_flag = False).columns\n",
    "    \n",
    "    mock_df = pd.DataFrame(index=pred_df.index.copy())\n",
    "\n",
    "    for column in columns:\n",
    "        mock_df[column] = 0.0\n",
    "\n",
    "    return mock_df\n",
    "\n",
    "\n",
    "\n",
    "def combine_features(channel_2_lists_dict):\n",
    "    features_format = [f_format for channel, (f_format, _ )  in channel_2_lists_dict.items()]\n",
    "    label_format = [l_format for channel, (_, l_format)  in channel_2_lists_dict.items()][0]\n",
    "    \n",
    "    features_format = np.concatenate(features_format,axis=2)\n",
    "    \n",
    "    return features_format, label_format\n",
    "    \n",
    "\n",
    "    \n",
    "def scale_features(features_format, scaler = None):\n",
    "    \n",
    "    nr_examples, timesteps, nr_features = features_format.shape    \n",
    "    reshaped_features = np.reshape(features_format,(nr_examples*timesteps,nr_features))\n",
    "    \n",
    "    if(scaler == None):\n",
    "        scaler = MinMaxScaler() \n",
    "#         scaler = StandardScaler()\n",
    "#         scaler = MaxAbsScaler()\n",
    "#         scaler = RobustScaler()\n",
    "        \n",
    "        scaler = scaler.fit(reshaped_features)\n",
    "\n",
    "    reshaped_features = scaler.transform(reshaped_features)\n",
    "    features_format = np.reshape(reshaped_features,(nr_examples,timesteps,nr_features))\n",
    "    \n",
    "    return features_format, scaler\n",
    "\n",
    "\n",
    "def standardize(f_df, l_df, timesteps, with_windows):\n",
    "    \n",
    "    data_timesteps = f_df.shape[1]\n",
    "    \n",
    "    max_timesteps = int(data_timesteps / timesteps) * timesteps\n",
    "\n",
    "    if(max_timesteps == 0):\n",
    "#         print(\"data_timesteps = {}\".format(data_timesteps))\n",
    "#         print(\"timesteps = {}\".format(timesteps))\n",
    "#         print(\"max_timesteps = {}\".format(max_timesteps))\n",
    "\n",
    "        f_matrix = f_df.as_matrix()\n",
    "        f_matrix = pad_sequences(f_matrix, maxlen=timesteps, dtype='float64',padding='post', \n",
    "                                 truncating='post', value=-1333)\n",
    "        f_matrix = np.expand_dims(np.transpose(f_matrix,(1,0)),axis=0)\n",
    "        \n",
    "        \n",
    "        l_matrix = l_df.as_matrix()\n",
    "        l_matrix = pad_sequences(l_matrix, maxlen=timesteps, dtype='float64',padding='post', \n",
    "                                 truncating='post', value=-1333)    \n",
    "        l_matrix = np.expand_dims(np.transpose(l_matrix,(1,0)),axis=0)\n",
    "\n",
    "        return f_matrix,l_matrix\n",
    "    \n",
    "    f_df = f_df.iloc[:,:max_timesteps]\n",
    "    l_df = l_df.iloc[:,:max_timesteps]\n",
    "        \n",
    "    if with_windows:\n",
    "        \n",
    "        f_df_windows = []\n",
    "        l_df_windows = []\n",
    "        \n",
    "        for window_start in range(max(1,max_timesteps - timesteps)):\n",
    "            window_end = window_start + timesteps\n",
    "            f_df_window = f_df.iloc[:,window_start:window_end]\n",
    "            l_df_window = l_df.iloc[:,window_start:window_end]\n",
    "\n",
    "            f_df_windows.append(f_df_window.T.as_matrix())\n",
    "            l_df_windows.append(l_df_window.T.as_matrix())\n",
    "\n",
    "\n",
    "        f_df_windows = np.stack(f_df_windows)\n",
    "        l_df_windows = np.stack(l_df_windows)\n",
    "\n",
    "        return f_df_windows, l_df_windows\n",
    "\n",
    "    else:\n",
    "        nr_splits = int(max_timesteps / timesteps)\n",
    "\n",
    "        f_matrix = pd.concat(np.array_split(f_df,nr_splits)).T.as_matrix()\n",
    "        l_matrix = pd.concat(np.array_split(l_df,nr_splits)).T.as_matrix()\n",
    "\n",
    "        f_matrix_list = np.array_split(f_matrix,nr_splits)\n",
    "        l_matrix_list = np.array_split(l_matrix,nr_splits)\n",
    "\n",
    "        f_stacked_matrix = np.stack(f_matrix_list)\n",
    "        l_stacked_matrix = np.stack(l_matrix_list)\n",
    "\n",
    "        return f_stacked_matrix, l_stacked_matrix\n",
    "    \n",
    "\n",
    "\n",
    "def construct_format_data(joined_list, timesteps, with_windows):\n",
    "\n",
    "    tuple_list = [standardize(features_df, labels_df, timesteps, with_windows) for features_df, labels_df in tqdm(joined_list)]\n",
    "    \n",
    "    features_list = [f for f,_ in tuple_list]\n",
    "    label_list = [l for _,l in tuple_list]\n",
    "    \n",
    "    features_list = np.vstack(features_list)\n",
    "    label_list = np.vstack(label_list)\n",
    "        \n",
    "    return features_list, label_list\n",
    "\n",
    "def filter_zeros(df):\n",
    "    df['sum_row'] = df.sum(axis=1)\n",
    "    \n",
    "    non_zero_index = -1\n",
    "\n",
    "    for i,(_,row) in enumerate(df.iterrows()):\n",
    "        if row['sum_row'] !=0 :\n",
    "            non_zero_index = i\n",
    "            break\n",
    "\n",
    "    for index in range(len(df)):\n",
    "        row = df.iloc[index]\n",
    "\n",
    "        if(row['sum_row'] == 0):\n",
    "            df.iloc[index] = df.iloc[non_zero_index].values\n",
    "        else:\n",
    "            non_zero_index = index\n",
    "        \n",
    "#     print(\"Number of zeros = {}\".format(len(df[df['sum_row'] == 0])))\n",
    "    \n",
    "    df = df.drop(['sum_row'],axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_df(path, column_names, round_decimals, no_drop_flag):\n",
    "    df = pd.read_csv(path, skiprows = 1, names = column_names)\n",
    "\n",
    "    if(round_decimals != -1):\n",
    "        df.loc[:,'Time'] = df.loc[:,'Time'].apply(lambda time: round(time,round_decimals))\n",
    "    \n",
    "    if(round_decimals == 0):\n",
    "        df.loc[:,'Time'] = df.loc[:,'Time'].apply(lambda time: int(time))\n",
    "        \n",
    "    prev_len = len(df)\n",
    "    df = df.drop_duplicates(\"Time\")\n",
    "    post_len = len(df)\n",
    "    \n",
    "    if(no_drop_flag):\n",
    "        assert(prev_len == post_len)\n",
    "    \n",
    "    df = df.set_index(\"Time\")\n",
    "    \n",
    "#     df = filter_zeros(df)\n",
    "   \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_data(base_path, data_channel, round_decimals, \\\n",
    "             label_folder, no_drop_flag, remove_extra_column, filter_agreement_score, \\\n",
    "             start_index, end_index):\n",
    "\n",
    "    pred_folder = base_path + label_folder + \"/\"\n",
    "    takes_names = sorted(os.listdir(pred_folder))\n",
    "\n",
    "    joined_list = []\n",
    "    \n",
    "    if(end_index == None):\n",
    "        end_index = len(takes_names)\n",
    "\n",
    "    takes_names = takes_names[start_index:end_index]\n",
    "\n",
    "    for take_name in tqdm(takes_names):\n",
    "\n",
    "        pred_path = pred_folder + take_name\n",
    "        data_channel_path = base_path + data_channel + \"/\" + take_name\n",
    "                    \n",
    "        pred_df = read_df(pred_path, \\\n",
    "                          channel_columns[label_folder],\n",
    "                          round_decimals = round_decimals,\n",
    "                          no_drop_flag = no_drop_flag)\n",
    "        \n",
    "        try:\n",
    "            data_df = read_df(data_channel_path, \\\n",
    "                              channel_columns[data_channel],\n",
    "                              round_decimals = round_decimals,\n",
    "                              no_drop_flag = no_drop_flag)\n",
    "            \n",
    "        except Exception as e:\n",
    "            data_channel_folder = base_path + data_channel + \"/\"\n",
    "            data_df = get_mock_df(pred_df, data_channel_folder, round_decimals)\n",
    "         \n",
    "        joined_df = pred_df.join(data_df) #left join\n",
    "        joined_df = joined_df.fillna(0.0)\n",
    "    \n",
    "#         joined_df = filter_zeros(joined_df)\n",
    "    \n",
    "        assert len(pred_df) == len(joined_df) \n",
    "        \n",
    "        if(len(joined_df) <= timesteps):\n",
    "                continue\n",
    "                \n",
    "        if filter_agreement_score:\n",
    "            joined_df = joined_df[joined_df[\"Agreement score\"] > 0.3]    \n",
    "            if(len(joined_df) <= timesteps):\n",
    "                continue\n",
    "        \n",
    "        joined_df = joined_df.T\n",
    "        \n",
    "        if remove_extra_column: # split features / labels df\n",
    "            features_df = joined_df[(NR_LABELS+1):] # eliminate the 'Agreement Score'\n",
    "        else:\n",
    "            features_df = joined_df[NR_LABELS:]\n",
    "        \n",
    "        label_df = joined_df[:NR_LABELS]\n",
    "            \n",
    "\n",
    "        joined_list.append((features_df, label_df))\n",
    "    \n",
    "\n",
    "    return joined_list\n",
    "\n",
    "\n",
    "def construct_channel_2_data_dict(base_path, channels, round_decimals, \n",
    "                                  timesteps, label_folder, no_drop_flag, remove_extra_column,\n",
    "                                  with_windows,filter_agreement_score, start_index, end_index):\n",
    "    channel_2_data_dict = {}\n",
    "    for channel in channels:\n",
    "        print(\"Channel = {}\".format(channel))\n",
    "        joined_list = get_data(base_path, channel, \n",
    "                               round_decimals = round_decimals, \n",
    "                               label_folder = label_folder, \n",
    "                               no_drop_flag = no_drop_flag,\n",
    "                               remove_extra_column = remove_extra_column,\n",
    "                               filter_agreement_score = filter_agreement_score,\n",
    "                               start_index = start_index,\n",
    "                               end_index = end_index) \n",
    "        \n",
    "        print(\"construct_format_data....\")\n",
    "        features_list, label_list = construct_format_data(joined_list, timesteps, with_windows)\n",
    "        \n",
    "        channel_2_data_dict[channel] = (features_list, label_list)\n",
    "    \n",
    "    return channel_2_data_dict\n",
    "\n",
    "def pipeline(start_index, end_index, with_windows, filter_agreement_score):\n",
    "    \n",
    "    # Construct data per channel\n",
    "    channel_2_data_dict =  construct_channel_2_data_dict(train_base_path, \\\n",
    "                                                     channels = channels, \\\n",
    "                                                     round_decimals = round_decimals,\n",
    "                                                     label_folder = 'labels',\n",
    "                                                     timesteps = timesteps,\n",
    "                                                     no_drop_flag = False,\n",
    "                                                     remove_extra_column = True,\n",
    "                                                     with_windows = with_windows,\n",
    "                                                     filter_agreement_score = filter_agreement_score,\n",
    "                                                     start_index = start_index,\n",
    "                                                     end_index = end_index) \n",
    "    \n",
    "    print(\"Constructed channel_2_data_dict...\")\n",
    "    \n",
    "    for channel, (features, labels)  in channel_2_data_dict.items():\n",
    "        print(channel)\n",
    "        print(features.shape)\n",
    "        print(labels.shape)\n",
    "        \n",
    "        \n",
    "    # Combine channels\n",
    "    \n",
    "    features, labels = combine_features(channel_2_data_dict)\n",
    "    \n",
    "    features, labels = shuffle(features,labels,random_state=0)\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def bring_to_standard_format(features,labels,test_timesteps):\n",
    "    nr_splits = int(test_timesteps / timesteps)\n",
    "\n",
    "    features_list = np.array_split(features,nr_splits,axis=1)\n",
    "    label_list = np.array_split(labels,nr_splits,axis=1)\n",
    "\n",
    "    features = np.vstack(features_list)\n",
    "    labels = np.vstack(label_list)\n",
    "\n",
    "    return features,labels\n",
    "\n",
    "def filter_entries_with_valid_data(features,labels):\n",
    "    min_wrong_index = [i for i,f in enumerate(features) if -1333 in f][0]\n",
    "    \n",
    "    features = features[:min_wrong_index]\n",
    "    labels = labels[:min_wrong_index]\n",
    "    \n",
    "    return features, labels\n",
    "        \n",
    "def round_preds(preds):\n",
    "\n",
    "    rounded_preds = np.zeros(preds.shape).astype(np.uint8)\n",
    "    for index, pred in enumerate(preds):\n",
    "        max_pred_index = np.argmax(pred)\n",
    "        rounded_preds[index][max_pred_index] = 1\n",
    "        \n",
    "    return rounded_preds       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_columns = {}\n",
    "channel_columns['audio'] = \"Time,Loudness_sma3,alphaRatio_sma3,hammarbergIndex_sma3,slope0-500_sma3,slope500-1500_sma3,spectralFlux_sma3,mfcc1_sma3,mfcc2_sma3,mfcc3_sma3,mfcc4_sma3,F0semitoneFrom27.5Hz_sma3nz,jitterLocal_sma3nz,shimmerLocaldB_sma3nz,HNRdBACF_sma3nz,logRelF0-H1-H2_sma3nz,logRelF0-H1-A3_sma3nz,F1frequency_sma3nz,F1bandwidth_sma3nz,F1amplitudeLogRelF0_sma3nz,F2frequency_sma3nz,F2amplitudeLogRelF0_sma3nz,F3frequency_sma3nz,F3amplitudeLogRelF0_sma3nz,pcm_fftMag_mfcc[0],pcm_fftMag_mfcc[1],pcm_fftMag_mfcc[2],pcm_fftMag_mfcc[3],pcm_fftMag_mfcc[4],pcm_fftMag_mfcc[5],pcm_fftMag_mfcc[6],pcm_fftMag_mfcc[7],pcm_fftMag_mfcc[8],pcm_fftMag_mfcc[9],pcm_fftMag_mfcc[10],pcm_fftMag_mfcc[11],pcm_fftMag_mfcc[12]\".split(\",\")\n",
    "channel_columns['eyes'] = \"Time,Eyes_F_1,Eyes_F_2,Eyes_F_3,Eyes_F_4,Eyes_F_5,Eyes_F_6\".split(\",\")\n",
    "channel_columns['face_nn'] = [\"Time\"] + [\"Face_F_\"+str(i) for i in range(100)]\n",
    "channel_columns['kinect'] = \"Time,Dist_hands,Dist_LH_hip_center,Dist_RH_hip_center,Dist_spine_hip,Dist_LSh_head,Dist_RSh_head,Dist_spine_head,Dist_LH_spine,Dist_RH_spine,Dist_LH_head,Dist_RH_head,Symmetry_hands,RH_velocity,RH_Smoothness_Index,RH_jerk,RH_Curvature_Index,RH_acceleration,LH_velocity,LH_Smoothness_Index,LH_jerk,LH_Curvature_Index,LH_acceleration,Kinetic_Energy,Head_velocity,Head_jerk,Head_acceleration,Density_Index\".split(\",\")\n",
    "channel_columns['labels'] = \"Time,Anger,Sad,Disgust,Happy,Scared,Neutral,Agreement score\".split(\",\")\n",
    "channel_columns['prediction'] = \"Time,Anger,Sad,Disgust,Happy,Scared,Neutral\".split(\",\")\n",
    "channel_columns['features'] = \"Anger,Sad,Disgust,Happy,Scared,Neutral\".split(\",\")\n",
    "\n",
    "NR_LABELS = 6\n",
    "\n",
    "train_base_path = \"./data/train/\"\n",
    "test_base_path = \"./data/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channels = ['audio', 'eyes', 'kinect', 'face_nn']\n",
    "# channels = ['face_nn']\n",
    "\n",
    "round_decimals = 0 # 0 -> 2\n",
    "timesteps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "218\n"
     ]
    }
   ],
   "source": [
    "nr_examples = len(os.listdir(train_base_path+\"labels\"))\n",
    "\n",
    "train_percentage = 0.7\n",
    "barrier = int(nr_examples * train_percentage)\n",
    "\n",
    "print(nr_examples)\n",
    "print(barrier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_start = 0\n",
    "train_end = barrier\n",
    "\n",
    "test_start = barrier + 1\n",
    "test_end = None\n",
    "\n",
    "# train_start = 0\n",
    "# train_end = 5\n",
    "\n",
    "# test_start = 5 \n",
    "# test_end = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/218 [00:00<00:12, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel = audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:07<00:00, 27.56it/s]\n",
      " 10%|█         | 22/217 [00:00<00:00, 212.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:00<00:00, 244.48it/s]\n",
      "  2%|▏         | 4/218 [00:00<00:05, 39.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel = eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:04<00:00, 44.76it/s]\n",
      " 10%|▉         | 21/217 [00:00<00:00, 208.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:00<00:00, 234.54it/s]\n",
      "  2%|▏         | 4/218 [00:00<00:05, 36.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel = kinect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:04<00:00, 47.71it/s]\n",
      " 10%|▉         | 21/217 [00:00<00:00, 205.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:00<00:00, 221.91it/s]\n",
      "  0%|          | 0/218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel = face_nn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:17<00:00, 12.70it/s]\n",
      " 16%|█▌        | 35/217 [00:00<00:00, 349.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:00<00:00, 334.50it/s]\n",
      "  2%|▏         | 2/93 [00:00<00:05, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed channel_2_data_dict...\n",
      "kinect\n",
      "(765, 10, 27)\n",
      "(765, 10, 6)\n",
      "eyes\n",
      "(765, 10, 6)\n",
      "(765, 10, 6)\n",
      "audio\n",
      "(765, 10, 36)\n",
      "(765, 10, 6)\n",
      "face_nn\n",
      "(765, 10, 100)\n",
      "(765, 10, 6)\n",
      "(765, 10, 169)\n",
      "(765, 10, 6)\n",
      "Channel = audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:03<00:00, 28.72it/s]\n",
      " 27%|██▋       | 25/92 [00:00<00:00, 243.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 260.49it/s]\n",
      "  6%|▋         | 6/93 [00:00<00:01, 57.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel = eyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:01<00:00, 62.74it/s]\n",
      " 25%|██▌       | 23/92 [00:00<00:00, 224.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 254.50it/s]\n",
      "  3%|▎         | 3/93 [00:00<00:03, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel = kinect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:01<00:00, 52.88it/s]\n",
      " 24%|██▍       | 22/92 [00:00<00:00, 216.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 250.64it/s]\n",
      "  1%|          | 1/93 [00:00<00:11,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel = face_nn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:06<00:00, 14.53it/s]\n",
      " 23%|██▎       | 21/92 [00:00<00:00, 209.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct_format_data....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92/92 [00:00<00:00, 243.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed channel_2_data_dict...\n",
      "kinect\n",
      "(320, 10, 27)\n",
      "(320, 10, 6)\n",
      "eyes\n",
      "(320, 10, 6)\n",
      "(320, 10, 6)\n",
      "audio\n",
      "(320, 10, 36)\n",
      "(320, 10, 6)\n",
      "face_nn\n",
      "(320, 10, 100)\n",
      "(320, 10, 6)\n",
      "(320, 10, 169)\n",
      "(320, 10, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = pipeline(train_start, \n",
    "                                        train_end, \n",
    "                                        with_windows = False,\n",
    "                                        filter_agreement_score = False)\n",
    "\n",
    "test_features, test_labels = pipeline(test_start, test_end,\n",
    "                                        with_windows = False,\n",
    "                                        filter_agreement_score = False,\n",
    "                                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 10, 169)\n",
      "(320, 10, 169)\n",
      "(765, 10, 6)\n",
      "(320, 10, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 10, 169)\n",
      "(320, 10, 169)\n"
     ]
    }
   ],
   "source": [
    "train_features,scaler = scale_features(train_features)\n",
    "test_features,_ = scale_features(test_features,scaler)\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reversed_train_features = np.flip(train_features,axis=1)\n",
    "# reversed_train_labels = np.flip(train_labels,axis=1)\n",
    "\n",
    "# train_features = np.vstack([train_features,reversed_train_features])\n",
    "# train_labels = np.vstack([train_labels,reversed_train_labels])\n",
    "\n",
    "# print(train_features.shape)\n",
    "# print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_product(features):\n",
    "    first_halves = features[:,:timesteps/2,:]\n",
    "    second_halves = features[:,timesteps/2:,:]\n",
    "    \n",
    "    print(first_halves.shape)\n",
    "    print(second_halves.shape)\n",
    "    \n",
    "    first_halves_list = list(first_halves)\n",
    "    second_halves_list = list(second_halves)\n",
    "\n",
    "    print(len(first_halves_list))\n",
    "    print(len(second_halves_list))\n",
    "    \n",
    "    cross_product = list(itertools.product(first_halves_list,second_halves_list))\n",
    "\n",
    "    print(len(cross_product))\n",
    "    \n",
    "    merged_back = np.stack([np.vstack([a,b]) for a,b in tqdm(cross_product)])\n",
    "    \n",
    "    return merged_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/585225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 5, 169)\n",
      "(765, 5, 169)\n",
      "765\n",
      "765\n",
      "585225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585225/585225 [00:06<00:00, 86830.40it/s]\n",
      "  3%|▎         | 18645/585225 [00:00<00:03, 186418.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 5, 6)\n",
      "(765, 5, 6)\n",
      "765\n",
      "765\n",
      "585225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585225/585225 [00:02<00:00, 225462.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585225, 10, 169)\n",
      "(585225, 10, 6)\n"
     ]
    }
   ],
   "source": [
    "train_features = cross_product(train_features)\n",
    "train_labels = cross_product(train_labels)\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def data_split(features):\n",
    "    \n",
    "#     kinect_f = features[...,:27]\n",
    "#     eyes_f = features[...,27:33]\n",
    "#     audio_f = features[...,33:69]\n",
    "#     face_nn_f = features[...,69:]\n",
    "\n",
    "#     return kinect_f, eyes_f, audio_f, face_nn_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_kinect_f, train_eyes_f, train_audio_f, train_face_nn_f = data_split(train_features)\n",
    "# test_kinect_f, test_eyes_f, test_audio_f, test_face_nn_f = data_split(test_features)\n",
    "\n",
    "# print(train_kinect_f.shape)\n",
    "# print(train_eyes_f.shape)\n",
    "# print(train_audio_f.shape)\n",
    "# print(train_face_nn_f.shape)\n",
    "# print(\"----\")\n",
    "# print(test_kinect_f.shape)\n",
    "# print(test_eyes_f.shape)\n",
    "# print(test_audio_f.shape)\n",
    "# print(test_face_nn_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_lstm(features_shape):\n",
    "#     input_layer = Input(shape= (features_shape[1],features_shape[2]))\n",
    "#     x = GRU(16,return_sequences=True)(input_layer)\n",
    "#     x = TimeDistributed(Dense(128, activation='relu'))(x)    \n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     model = Model(input_layer, x)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# def get_conv1d(features_shape):\n",
    "#     input_layer = Input(shape= (features_shape[1],features_shape[2]))\n",
    "#     x = Conv1D(64,3,activation='relu', border_mode='same')(input_layer)\n",
    "#     x = TimeDistributed(Dense(128, activation='relu'))(x)    \n",
    "#     x = Dropout(0.5)(x)\n",
    "#     x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     model = Model(input_layer, x)\n",
    "    \n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kinect_lstm = get_conv1d(train_kinect_f.shape)\n",
    "# eyes_lstm = get_conv1d(train_eyes_f.shape)\n",
    "# audio_lstm = get_conv1d(train_audio_f.shape)\n",
    "# face_nn_lstm = get_conv1d(train_face_nn_f.shape)\n",
    "\n",
    "# lstm_list = [kinect_lstm, eyes_lstm, audio_lstm, face_nn_lstm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # model.add(Merge(lstm_list, mode='concat'))\n",
    "# model.add(Merge(lstm_list, mode='sum'))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(32, activation = 'relu')))\n",
    "\n",
    "# model.add(TimeDistributed(Dense(NR_LABELS, activation = 'softmax')))\n",
    "# model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "# display(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit([train_kinect_f, train_eyes_f, train_audio_f, train_face_nn_f], train_labels,\n",
    "#           nb_epoch = 200,\n",
    "#           batch_size = 128,\n",
    "#           validation_data = ([test_kinect_f, test_eyes_f, test_audio_f, test_face_nn_f], test_labels),\n",
    "#           callbacks = [\n",
    "#                   CSVLogger(\"./training.txt\"),\n",
    "#                   ModelCheckpoint(\"./models/model_temp.h5\", monitor='val_acc', verbose= 1, save_best_only=True, mode='max')\n",
    "#          ]\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save_weights(\"./models/all_model_split.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights(\"./models/model_temp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_acc = model.evaluate([train_kinect_f, train_eyes_f, train_audio_f, train_face_nn_f],train_labels)[1]\n",
    "# test_acc = model.evaluate([test_kinect_f, test_eyes_f, test_audio_f, test_face_nn_f],test_labels)[1]\n",
    "\n",
    "# print(\"\\n\\nTrain acc = {}\".format(train_acc))\n",
    "# print(\"Test acc = {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # train_features = resh(train_features)\n",
    "# # train_labels = resh(train_labels)\n",
    "# # test_features = resh(test_features)\n",
    "# # test_labels = resh(test_labels)\n",
    "\n",
    "\n",
    "# print(train_features.shape)\n",
    "# print(train_labels.shape)\n",
    "# print(test_features.shape)\n",
    "# print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_layer = Input(shape= (169,))\n",
    "# x = Dense(128, activation='relu')(input_layer)    \n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# pred_layer = Dense(NR_LABELS, activation='softmax')(x)\n",
    "\n",
    "# model = Model(input_layer, pred_layer)\n",
    "# model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit(train_features, train_labels,\n",
    "#           nb_epoch = 500,\n",
    "#           batch_size = 128,\n",
    "#           validation_data = (test_features, test_labels),\n",
    "#           callbacks = [\n",
    "#                   CSVLogger(\"./training.txt\"),\n",
    "#                   ModelCheckpoint(\"./models/model_temp.h5\", monitor='val_acc', verbose= 1, save_best_only=True, mode='max')\n",
    "#          ]\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def resh(f):\n",
    "#     return np.reshape(f,(f.shape[0],f.shape[1]*f.shape[2]))\n",
    "\n",
    "# def sklearn_predict(clf,features):\n",
    "#     test_pred = clf.predict(features)\n",
    "#     test_preds_ohe = np.zeros((len(features),6))\n",
    "\n",
    "#     for i,pred in enumerate(test_pred):\n",
    "#         test_preds_ohe[i][pred] = 1\n",
    "    \n",
    "#     return test_preds_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_features = resh(train_features)\n",
    "# train_labels = resh(train_labels)\n",
    "# test_features = resh(test_features)\n",
    "# test_labels = resh(test_labels)\n",
    "\n",
    "\n",
    "# print(train_features.shape)\n",
    "# print(train_labels.shape)\n",
    "# print(test_features.shape)\n",
    "# print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_labels_nr = np.array([np.argmax(l) for l in train_labels])\n",
    "# test_labels_nr = np.array([np.argmax(l) for l in test_labels])\n",
    "\n",
    "# print(train_labels_nr.shape)\n",
    "# print(test_labels_nr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=100, verbose=1, n_jobs=24)\n",
    "# # clf = GradientBoostingClassifier(n_estimators = 500, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf.fit(train_features, train_labels_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_preds_ohe = sklearn_predict(clf,test_features)\n",
    "# accuracy_score(test_labels, test_preds_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_preds_ohe = test_preds_ohe = sklearn_predict(clf,train_features)\n",
    "# accuracy_score(train_labels, train_preds_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape= (train_features.shape[1],train_features.shape[2]))\n",
    "x = GRU(16,return_sequences=True)(input_layer)\n",
    "\n",
    "x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = TimeDistributed(Dense(64, activation='relu'))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "pred_layer = TimeDistributed(Dense(NR_LABELS, activation='softmax'))(x)\n",
    "\n",
    "model = Model(input_layer, pred_layer)\n",
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 585225 samples, validate on 320 samples\n",
      "Epoch 1/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.7976 - acc: 0.7143Epoch 00000: val_acc improved from -inf to 0.56937, saving model to ./models/model_temp.h5\n",
      "585225/585225 [==============================] - 68s - loss: 0.7976 - acc: 0.7143 - val_loss: 1.5298 - val_acc: 0.5694\n",
      "Epoch 2/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8404Epoch 00001: val_acc improved from 0.56937 to 0.57000, saving model to ./models/model_temp.h5\n",
      "585225/585225 [==============================] - 66s - loss: 0.4715 - acc: 0.8404 - val_loss: 2.0199 - val_acc: 0.5700\n",
      "Epoch 3/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.3726 - acc: 0.8756Epoch 00002: val_acc improved from 0.57000 to 0.57031, saving model to ./models/model_temp.h5\n",
      "585225/585225 [==============================] - 66s - loss: 0.3726 - acc: 0.8756 - val_loss: 2.2562 - val_acc: 0.5703\n",
      "Epoch 4/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.8953Epoch 00003: val_acc did not improve\n",
      "585225/585225 [==============================] - 64s - loss: 0.3162 - acc: 0.8953 - val_loss: 2.6069 - val_acc: 0.5659\n",
      "Epoch 5/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.2798 - acc: 0.9080Epoch 00004: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.2798 - acc: 0.9080 - val_loss: 2.9409 - val_acc: 0.5641\n",
      "Epoch 6/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9174Epoch 00005: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.2526 - acc: 0.9174 - val_loss: 3.1307 - val_acc: 0.5522\n",
      "Epoch 7/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9247Epoch 00006: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.2317 - acc: 0.9247 - val_loss: 3.4192 - val_acc: 0.5175\n",
      "Epoch 8/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9306Epoch 00007: val_acc did not improve\n",
      "585225/585225 [==============================] - 64s - loss: 0.2143 - acc: 0.9306 - val_loss: 3.4101 - val_acc: 0.5544\n",
      "Epoch 9/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9353Epoch 00008: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.2003 - acc: 0.9353 - val_loss: 3.5558 - val_acc: 0.5416\n",
      "Epoch 10/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9393Epoch 00009: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1887 - acc: 0.9393 - val_loss: 3.8576 - val_acc: 0.5409\n",
      "Epoch 11/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9427Epoch 00010: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1790 - acc: 0.9427 - val_loss: 3.9134 - val_acc: 0.5453\n",
      "Epoch 12/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9460Epoch 00011: val_acc did not improve\n",
      "585225/585225 [==============================] - 66s - loss: 0.1689 - acc: 0.9460 - val_loss: 4.1641 - val_acc: 0.5344\n",
      "Epoch 13/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9487Epoch 00012: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1609 - acc: 0.9487 - val_loss: 4.0638 - val_acc: 0.5381\n",
      "Epoch 14/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9514 - ETA: 0s - Epoch 00013: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1527 - acc: 0.9514 - val_loss: 4.4177 - val_acc: 0.5353\n",
      "Epoch 15/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9533Epoch 00014: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1468 - acc: 0.9533 - val_loss: 4.3694 - val_acc: 0.5316\n",
      "Epoch 16/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9546Epoch 00015: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1428 - acc: 0.9546 - val_loss: 4.5766 - val_acc: 0.5325\n",
      "Epoch 17/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9564Epoch 00016: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1377 - acc: 0.9564 - val_loss: 4.6097 - val_acc: 0.5366\n",
      "Epoch 18/100\n",
      "585216/585225 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9579Epoch 00017: val_acc did not improve\n",
      "585225/585225 [==============================] - 65s - loss: 0.1331 - acc: 0.9579 - val_loss: 4.6643 - val_acc: 0.5409\n",
      "Epoch 19/100\n",
      "174464/585225 [=======>......................] - ETA: 46s - loss: 0.1285 - acc: 0.9591"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c020d1e96caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           callbacks = [\n\u001b[1;32m      6\u001b[0m                   \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                   \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/model_temp.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m          ]\n\u001b[1;32m      9\u001b[0m          )\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_features, train_labels,\n",
    "          nb_epoch = 100,\n",
    "          batch_size = 128,\n",
    "          validation_data = (test_features, test_labels),\n",
    "          callbacks = [\n",
    "                  CSVLogger(\"./training.txt\"),\n",
    "                  ModelCheckpoint(\"./models/model_temp.h5\", monitor='val_acc', verbose= 1, save_best_only=True, mode='max')\n",
    "         ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "# model.save_weights(\"./models/model_last_epoch.h5\")\n",
    "# model.save_weights(\"./models/scaled_augmented_acc=70.h5\")\n",
    "# model.save_weights(\"./models/all_scaled_decimals=0_lstm=16_v3.h5\")\n",
    "model.save_weights(\"./models/all_scaled_decimals=0_gru=16_epoch=600.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load weights\n",
    "\n",
    "# model.load_weights(\"./models/model_last_epoch.h5\")\n",
    "# model.load_weights(\"./models/model_temp.h5\")\n",
    "\n",
    "# model.load_weights(\"./models/scaled_augmented_acc=70.h5\")\n",
    "# model.load_weights(\"./models/all_scaled_decimals=0_gru=16_epoch=372.h5\")\n",
    "# model.load_weights(\"./models/scaled_decimals=0_gru=16_acc=61.h5\")\n",
    "# model.load_weights(\"./models/all_scaled_decimals=0_lstm=16_v3.h5\")\n",
    "\n",
    "model.load_weights(\"./models/all_scaled_decimals=0_gru=16_epoch=200.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_acc = model.evaluate(train_features,train_labels)[1]\n",
    "test_acc = model.evaluate(test_features,test_labels)[1]\n",
    "\n",
    "print(\"\\n\\nTrain acc = {}\".format(train_acc))\n",
    "print(\"Test acc = {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(base_path, label_folder, is_train = False):\n",
    "    \n",
    "    prediction_path = base_path + \"/\" + label_folder + \"/\"\n",
    "    nr_examples = len(os.listdir(prediction_path))\n",
    "    take_names = sorted(os.listdir(prediction_path))\n",
    "\n",
    "    test_timesteps = 10000\n",
    "    \n",
    "    pred_df_2_take_name_list = []\n",
    "    \n",
    "    for csv_index in tqdm(range(nr_examples)):\n",
    "\n",
    "        test_channel_2_data_dict =  construct_channel_2_data_dict(base_path, \n",
    "                                                         channels = channels, \n",
    "                                                         round_decimals = round_decimals, \n",
    "                                                         label_folder = label_folder,\n",
    "                                                         timesteps = test_timesteps,\n",
    "                                                         no_drop_flag = False,\n",
    "                                                         remove_extra_column = is_train,\n",
    "                                                         with_windows = False,\n",
    "                                                         filter_agreement_score = False,\n",
    "                                                         start_index = csv_index,\n",
    "                                                         end_index = csv_index + 1) \n",
    "\n",
    "        \n",
    "        features, labels = combine_features(test_channel_2_data_dict)\n",
    "\n",
    "        features, labels = bring_to_standard_format(features,labels, test_timesteps)\n",
    "\n",
    "        features, labels = filter_entries_with_valid_data(features,labels)\n",
    "\n",
    "        features, _ = scale_features(features, scaler = scaler)\n",
    "        \n",
    "#         test_kinect_f, test_eyes_f, test_audio_f, test_face_nn_f = data_split(features)\n",
    "#         preds = model.predict([test_kinect_f, test_eyes_f, test_audio_f, test_face_nn_f])\n",
    "       \n",
    "        preds = model.predict(features)\n",
    "        \n",
    "        preds = preds.reshape(preds.shape[0] * preds.shape[1], preds.shape[2])\n",
    "        \n",
    "        preds = round_preds(preds)\n",
    "\n",
    "        take_name = take_names[csv_index]\n",
    "    \n",
    "        ########\n",
    "        \n",
    "        label_df = pd.read_csv(prediction_path + take_name, dtype=str)[['Time']]\n",
    "        label_df.loc[:,'Time_Bucket'] = label_df.loc[:,'Time'].apply(lambda time: round(float(time),round_decimals))\n",
    "\n",
    "        buckets = set(label_df['Time_Bucket'])\n",
    "        nr_buckets = len(buckets)\n",
    "        pred_length = len(preds)\n",
    "\n",
    "        preds_padded = np.zeros((nr_buckets,NR_LABELS))\n",
    "        preds_padded[:pred_length,:] = preds\n",
    "\n",
    "        last_pred_value = preds[-1]\n",
    "        preds_padded[pred_length:,:] = last_pred_value\n",
    "\n",
    "        bucket_2_pred = {bucket:pred for bucket,pred in zip(buckets,preds_padded)}\n",
    "\n",
    "        label_df.loc[:,'pred'] = label_df.loc[:,'Time_Bucket'].apply(lambda bucket: bucket_2_pred[bucket])\n",
    "\n",
    "        label_df[channel_columns['features']] = pd.DataFrame(label_df['pred'].values.tolist())\n",
    "        label_df = label_df.drop([\"Time_Bucket\",\"pred\"],axis=1)\n",
    "\n",
    "        #######\n",
    "        \n",
    "        for col in channel_columns['features']:\n",
    "            label_df[col] = label_df[col].astype(int)\n",
    "\n",
    "        pred_df_2_take_name_list.append((label_df,take_name))\n",
    "    \n",
    "    return pred_df_2_take_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_df_2_take_name_list = make_prediction(train_base_path, label_folder = 'labels', is_train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_df_2_take_name_list = make_prediction(test_base_path, label_folder = 'prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = \"./prediction/\"\n",
    "\n",
    "shutil.rmtree(output_path)\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pred_df, take_name in tqdm(pred_df_2_take_name_list):    \n",
    "    pred_df.to_csv(output_path + take_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm prediction.zip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_folder = \"./data/test/prediction/\"\n",
    "pred_folder = \"./prediction/\"\n",
    "\n",
    "test_paths = sorted(os.listdir(test_folder))\n",
    "pred_paths = sorted(os.listdir(pred_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(set(test_paths).difference(set(pred_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in tqdm(test_paths):\n",
    "    test_df = pd.read_csv(test_folder + path,dtype=str)\n",
    "    pred_df = pd.read_csv(pred_folder + path,dtype=str)\n",
    "    \n",
    "    matrix = pred_df.drop(\"Time\",axis=1).apply(pd.to_numeric).as_matrix()\n",
    "    \n",
    "    nr_rows = matrix.shape[0]\n",
    "    matrix_sum = np.sum(matrix)\n",
    "\n",
    "#     print(\"{} -> {}\".format(nr_rows,matrix_sum))\n",
    "\n",
    "    assert(len(set(test_df.index).difference(set(pred_df.index))) == 0)\n",
    "    assert(list(test_df.index) == list(pred_df.index))\n",
    "    assert(test_df.shape == pred_df.shape)\n",
    "    assert(nr_rows == matrix_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy_on_train_set(pred_df_2_take_name_list):\n",
    "    \n",
    "    global_pred_vector = []\n",
    "    global_gt_vector = []\n",
    "    for pred_df, take_name in tqdm(pred_df_2_take_name_list):\n",
    "\n",
    "        pred_df = pred_df.drop(['Time'],axis = 1)\n",
    "        gt_df = pd.read_csv(train_base_path + \"labels/\" + take_name, dtype=str)\\\n",
    "                    .drop([\"Time\",\"Agreement score\"],axis=1)\n",
    "\n",
    "        pred_matrix = pred_df.as_matrix()\n",
    "        gt_matrix = gt_df.as_matrix()\n",
    "\n",
    "        pred_vector = [np.argmax(x) for x in pred_matrix]\n",
    "        gt_vector = [np.argmax(x) for x in gt_matrix]\n",
    "\n",
    "        global_pred_vector += pred_vector\n",
    "        global_gt_vector += gt_vector\n",
    "        \n",
    "    return global_gt_vector, global_pred_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_vector, pred_vector = compute_accuracy_on_train_set(pred_df_2_take_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(gt_vector, pred_vector)        \n",
    "print(\"Train acc = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(gt_vector,pred_vector)\n",
    "plot_confusion_matrix(cnf_matrix, classes = channel_columns['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([channel_columns['features'][i] for i in gt_vector],columns=['gt']).groupby('gt').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([channel_columns['features'][i] for i in pred_vector],columns=['pred']).groupby('pred').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Replace 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = \"./data/train/audio/id1023e63c.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, skiprows = 1, names = channel_columns['audio'])\n",
    "df = df.set_index(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
